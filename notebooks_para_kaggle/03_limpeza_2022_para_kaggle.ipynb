{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7fac1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "sys.path.append('../src')\n",
    "import data_cleaner as dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14c91920",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_DIR, PROCESSED_DATA_DIR = dc.caminho_para_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54a0ddbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arquivo encontrado\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  df_2022_kaggle = pd.read_csv (PROCESSED_DATA_DIR / 'state_of_data_2022_limpo.csv')\n",
    "  print('arquivo encontrado')\n",
    "except FileNotFoundError as e: \n",
    "  print(\"Arquivo nao encontrado \" + e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bc5145b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id_participante', 'idade', 'faixa_idade', 'genero', 'etnia', 'pcd', 'experiencia_prejudicada', \"('P1_f ', 'aspectos_prejudicados')\", \"('P1_g ', 'vive_no_brasil')\", \"('P1_i ', 'Estado onde mora')\", 'uf_residencia', 'regiao_residencia', \"('P1_j ', 'Mudou de Estado?')\", 'regiao_origem', 'nivel_ensino', 'area_formacao', 'situacao_trabalho', 'setor_atuacao', 'tamanho_empresa', 'atua_como_gestor', \"('P2_e ', 'Cargo como Gestor')\", 'cargo_atual', 'nivel_hierarquico', 'faixa_salarial', 'experiencia_dados_anos', 'experiencia_ti_anos', 'satisfacao_trabalho', 'motivos_insatisfacao', \"('P2_l_1 ', 'Falta de oportunidade de crescimento no emprego atual')\", \"('P2_l_2 ', 'Salário atual não corresponde ao mercado')\", \"('P2_l_3 ', 'Não tenho uma boa relação com meu líder/gestor')\", \"('P2_l_4 ', 'Gostaria de trabalhar em em outra área de atuação')\", \"('P2_l_5 ', 'Gostaria de receber mais benefícios')\", \"('P2_l_6 ', 'O clima de trabalho/ambiente não é bom')\", \"('P2_l_7 ', 'Falta de maturidade analítica na empresa')\", 'entrevistas_ultimos_6m', 'planos_mudar_emprego', 'criterios_escolha_emprego', \"('P2_o_1 ', 'Remuneração/Salário')\", \"('P2_o_2 ', 'Benefícios')\", \"('P2_o_3 ', 'Propósito do trabalho e da empresa')\", \"('P2_o_4 ', 'Flexibilidade de trabalho remoto')\", \"('P2_o_5 ', 'Ambiente e clima de trabalho')\", \"('P2_o_6 ', 'Oportunidade de aprendizado e trabalhar com referências na área')\", \"('P2_o_7 ', 'Plano de carreira e oportunidades de crescimento profissional')\", \"('P2_o_8 ', 'Maturidade da empresa em termos de tecnologia e dados')\", \"('P2_o_9 ', 'Qualidade dos gestores e líderes')\", \"('P2_o_10 ', 'Reputação que a empresa tem no mercado')\", 'modelo_trabalho_atual', 'modelo_trabalho_ideal', \"('P2_r ', 'Caso sua empresa decida pelo modelo 100% presencial qual será sua atitude?')\", 'empresa_teve_layoff_2022', 'tamanho_equipe_dados', \"('P3_b ', 'Quais desses papéis/cargos fazem parte do time (ou chapter) de dados da sua empresa?')\", \"('P3_b_1 ', 'Analytics Engineer')\", \"('P3_b_2 ', 'Engenharia de Dados/Data Engineer')\", \"('P3_b_3 ', 'Analista de Dados/Data Analyst')\", \"('P3_b_4 ', 'Cientista de Dados/Data Scientist')\", \"('P3_b_5 ', 'Database Administrator/DBA')\", \"('P3_b_6 ', 'Analista de Business Intelligence/BI')\", \"('P3_b_7 ', 'Arquiteto de Dados/Data Architect')\", \"('P3_b_8 ', 'Data Product Manager/DPM')\", \"('P3_b_9 ', 'Business Analyst')\", \"('P3_c ', 'Quais dessas responsabilidades fazem parte da sua rotina atual de trabalho como gestor?')\", \"('P3_c_1 ', 'Pensar na visão de longo prazo de dados da empresa e fortalecimento da cultura analítica da companhia.')\", \"('P3_c_2 ', 'Organização de treinamentos e iniciativas com o objetivo de aumentar a maturidade analítica das áreas de negócios.')\", \"('P3_c_3 ', 'Atração, seleção e contratação de talentos para o time de dados.')\", \"('P3_c_4 ', 'Decisão sobre contratação de ferramentas e tecnologias relacionadas a dados.')\", \"('P3_c_5 ', 'Sou gestor da equipe responsável pela engenharia de dados e por manter o Data Lake da empresa como fonte única dos dados, garantindo a qualidade e confiabilidade da informação.')\", \"('P3_c_6 ', 'Sou gestor da equipe responsável pela entrega de dados, estudos, relatórios e dashboards para as áreas de negócio da empresa.')\", \"('P3_c_7 ', 'Sou gestor da equipe responsável por iniciativas e projetos envolvendo Inteligência Artificial e Machine Learning.')\", \"('P3_c_8 ', 'Apesar de ser gestor ainda atuo na parte técnica, construindo soluções/análises/modelos etc.')\", \"('P3_c_9 ', 'Gestão de projetos de dados, cuidando das etapas, equipes envolvidas, atingimento dos objetivos etc.')\", \"('P3_c_10 ', 'Gestão de produtos de dados, cuidando da visão dos produtos, backlog, feedback de usuários etc.')\", \"('P3_c_11 ', 'Gestão de pessoas, apoio no desenvolvimento das pessoas, evolução de carreira')\", 'desafios_gestor', \"('P3_d_1 ', 'a Contratar novos talentos.')\", \"('P3_d_2 ', 'b Reter talentos.')\", \"('P3_d_3 ', 'c Convencer a empresa a aumentar os investimentos na área de dados.')\", \"('P3_d_4 ', 'd Gestão de equipes no ambiente remoto.')\", \"('P3_d_5 ', 'e Gestão de projetos envolvendo áreas multidisciplinares da empresa.')\", \"('P3_d_6 ', 'f Organizar as informações e garantir a qualidade e confiabilidade.')\", \"('P3_d_7 ', 'g Conseguir processar e armazenar um alto volume de dados.')\", \"('P3_d_8 ', 'h Conseguir gerar valor para as áreas de negócios através de estudos e experimentos.')\", \"('P3_d_9 ', 'i Desenvolver e manter modelos Machine Learning em produção.')\", \"('P3_d_10 ', 'j Gerenciar a expectativa das áreas de negócio em relação as entregas das equipes de dados.')\", \"('P3_d_11 ', 'k Garantir a manutenção dos projetos e modelos em produção, em meio ao crescimento da empresa.')\", \"('P3_d_12 ', 'Conseguir levar inovação para a empresa através dos dados.')\", \"('P3_d_13 ', 'Garantir retorno do investimento (ROI) em projetos de dados.')\", \"('P3_d_14 ', 'Dividir o tempo entre entregas técnicas e gestão.')\", \"('P4_a ', 'Mesmo que esse não seja seu cargo formal, você considera que sua atuação no dia a dia, reflete alguma das opções listadas abaixo?')\", \"('P4_a_1 ', 'Atuacao')\", \"('P4_b ', 'Quais das fontes de dados listadas você já analisou ou processou no trabalho?')\", \"('P4_b_1 ', 'Dados relacionais (estruturados em bancos SQL)')\", \"('P4_b_2 ', 'Dados armazenados em bancos NoSQL')\", \"('P4_b_3 ', 'Imagens')\", \"('P4_b_4 ', 'Textos/Documentos')\", \"('P4_b_5 ', 'Vídeos')\", \"('P4_b_6 ', 'Áudios')\", \"('P4_b_7 ', 'Planilhas')\", \"('P4_b_8 ', 'Dados georeferenciados')\", \"('P4_c ', 'Entre as fontes de dados listadas, quais você utiliza na maior parte do tempo?')\", \"('P4_c_1 ', 'Dados relacionais (estruturados em bancos SQL)')\", \"('P4_c_2 ', 'Dados armazenados em bancos NoSQL')\", \"('P4_c_3 ', 'Imagens')\", \"('P4_c_4 ', 'Textos/Documentos')\", \"('P4_c_5 ', 'Vídeos')\", \"('P4_c_6 ', 'Áudios')\", \"('P4_c_7 ', 'Planilhas')\", \"('P4_c_8 ', 'Dados georeferenciados')\", 'linguagens_usadas_dia_a_dia', \"('P4_d_1 ', 'SQL')\", \"('P4_d_2 ', 'R ')\", \"('P4_d_3 ', 'Python')\", \"('P4_d_4 ', 'C/C++/C#')\", \"('P4_d_5 ', '.NET')\", \"('P4_d_6 ', 'Java')\", \"('P4_d_7 ', 'Julia')\", \"('P4_d_8 ', 'SAS/Stata')\", \"('P4_d_9 ', 'Visual Basic/VBA')\", \"('P4_d_10 ', 'Scala')\", \"('P4_d_11 ', 'Matlab')\", \"('P4_d_12 ', 'PHP')\", \"('P4_d_13 ', 'Javascript')\", \"('P4_d_14 ', 'Não utilizo nenhuma linguagem')\", 'linguagem_principal', 'linguagem_preferida', 'bancos_dados_usados_dia_a_dia', \"('P4_g_1 ', 'MySQL')\", \"('P4_g_2 ', 'Oracle')\", \"('P4_g_3 ', 'SQL SERVER')\", \"('P4_f_4 ', 'Amazon Aurora ou RDS')\", \"('P4_f_5 ', 'DynamoDB')\", \"('P4_f_6 ', 'CoachDB')\", \"('P4_f_7 ', 'Cassandra')\", \"('P4_f_8 ', 'MongoDB')\", \"('P4_f_9 ', 'MariaDB')\", \"('P4_f_10 ', 'Datomic')\", \"('P4_f_11 ', 'S3')\", \"('P4_f_12 ', 'PostgreSQL')\", \"('P4_f_13 ', 'ElasticSearch')\", \"('P4_f_14 ', 'DB2')\", \"('P4_f_15 ', 'Microsoft Access')\", \"('P4_f_16 ', 'SQLite')\", \"('P4_f_17 ', 'Sybase')\", \"('P4_f_18 ', 'Firebase')\", \"('P4_f_19 ', 'Vertica')\", \"('P4_f_20 ', 'Redis')\", \"('P4_f_21 ', 'Neo4J')\", \"('P4_f_22 ', 'Google BigQuery')\", \"('P4_f_23 ', 'Google Firestore')\", \"('P4_f_24 ', 'Amazon Redshift')\", \"('P4_f_25 ', 'Amazon Athena')\", \"('P4_f_26 ', 'Snowflake')\", \"('P4_f_27 ', 'Databricks')\", \"('P4_f_28 ', 'HBase')\", \"('P4_f_29 ', 'Presto')\", \"('P4_f_30 ', 'Splunk')\", \"('P4_f_31 ', 'SAP HANA')\", \"('P4_f_32 ', 'Hive')\", \"('P4_f_33 ', 'Firebird')\", 'clouds_utilizadas', 'cloud_preferida', \"('P4_h_1 ', 'Azure (Microsoft)')\", \"('P4_h_2 ', 'Amazon Web Services (AWS)')\", \"('P4_h_3 ', 'Google Cloud (GCP)')\", 'ferramentas_bi_usadas_dia_a_dia', \"('P4_i_1 ', 'Microsoft PowerBI')\", \"('P4_i_2 ', 'Qlik View/Qlik Sense')\", \"('P4_i_3 ', 'Tableau')\", \"('P4_i_4 ', 'Metabase')\", \"('P4_i_5 ', 'Superset')\", \"('P4_i_6 ', 'Redash')\", \"('P4_i_7 ', 'MicroStrategy')\", \"('P4_i_8 ', 'IBM Analytics/Cognos')\", \"('P4_i_9 ', 'SAP Business Objects')\", \"('P4_i_10 ', 'Oracle Business Intelligence')\", \"('P4_i_11 ', 'Amazon QuickSight')\", \"('P4_i_12 ', 'Salesforce/Einstein Analytics')\", \"('P4_i_13 ', 'Mode')\", \"('P4_i_14 ', 'Alteryx')\", \"('P4_i_15 ', 'Birst')\", \"('P4_i_16 ', 'Looker')\", \"('P4_i_17 ', 'Google Data Studio')\", \"('P4_i_18 ', 'SAS Visual Analytics')\", \"('P4_i_19 ', 'Grafana')\", \"('P4_i_20 ', 'TIBCO Spotfire')\", \"('P4_i_21 ', 'Pentaho')\", \"('P4_i_22 ', 'Fazemos todas as análises utilizando apenas Excel ou planilhas do google')\", \"('P4_i_23 ', 'Não utilizo nenhuma ferramenta de BI no trabalho')\", \"('P5_a ', 'Qual seu objetivo na área de dados?')\", 'tipo_oportunidade_buscada', 'tempo_busca_emprego_meses', \"('P5_d ', 'Como tem sido a busca por um emprego na área de dados?')\", \"('P6_a ', 'Quais das opções abaixo fazem parte da sua rotina no trabalho atual como engenheiro de dados?')\", \"('P6_a_1 ', 'Desenvolvo pipelines de dados utilizando linguagens de programação como Python, Scala, Java etc.')\", \"('P6_a_2 ', 'Realizo construções de ETL's em ferramentas como Pentaho, Talend, Dataflow etc.')\", \"('P6_a_3 ', 'Crio consultas através da linguagem SQL para exportar informações e compartilhar com as áreas de negócio.')\", \"('P6_a_4 ', 'Atuo na integração de diferentes fontes de dados através de plataformas proprietárias como Stitch Data, Fivetran etc.')\", \"('P6_a_5 ', 'Modelo soluções de arquitetura de dados, criando componentes de ingestão de dados, transformação e recuperação da informação.')\", \"('P6_a_6 ', 'Desenvolvo/cuido da manutenção de repositórios de dados baseados em streaming de eventos como Data Lakes e Data Lakehouses.')\", \"('P6_a_7 ', 'Atuo na modelagem dos dados, com o objetivo de criar conjuntos de dados como Data Warehouses, Data Marts etc.')\", \"('P6_a_8 ', 'Cuido da qualidade dos dados, metadados e dicionário de dados.')\", \"('P6_a_9 ', 'Nenhuma das opções listadas refletem meu dia a dia.')\", \"('P6_b ', 'Quais as ferramentas/tecnologias de ETL que você utiliza no trabalho como Data Engineer?')\", \"('P6_b_1 ', 'Scripts Python')\", \"('P6_b_2 ', 'SQL & Stored Procedures')\", \"('P6_b_3 ', 'Apache Airflow')\", \"('P6_b_4 ', 'Luigi')\", \"('P6_b_5 ', 'AWS Glue')\", \"('P6_b_6 ', 'Talend')\", \"('P6_b_7 ', 'Pentaho')\", \"('P6_b_8 ', 'Alteryx')\", \"('P6_b_9 ', 'Stitch')\", \"('P6_b_10 ', 'Fivetran')\", \"('P6_b_11 ', 'Google Dataflow')\", \"('P6_b_12 ', 'Oracle Data Integrator')\", \"('P6_b_13 ', 'IBM DataStage')\", \"('P6_b_14 ', 'SAP BW ETL')\", \"('P6_b_15 ', 'SQL Server Integration Services (SSIS)')\", \"('P6_b_16 ', 'SAS Data Integration')\", \"('P6_b_17 ', 'Qlik Sense')\", \"('P6_b_18 ', 'Knime')\", \"('P6_b_19 ', 'Databricks')\", \"('P6_b_19 ', 'Não utilizo ferramentas de ETL')\", \"('P6_c ', 'Sua organização possui um Data Lake?')\", \"('P6_d ', 'Qual tecnologia utilizada como plataforma do Data Lake?')\", \"('P6_e ', 'Sua organização possui um Data Warehouse?')\", \"('P6_f ', 'Qual tecnologia utilizada como plataforma do Data Warehouse?')\", \"('P6_g ', 'Quais as ferramentas de gestão de Qualidade de dados, Metadados e catálogo de dados você utiliza no trabalho?')\", \"('P6_g_1 ', 'great_expectations')\", \"('P6_g_2 ', 'dbt')\", \"('P6_g_3 ', 'AWS Deequ')\", \"('P6_g_4 ', 'Apache Griffin')\", \"('P6_g_5 ', 'Datafold')\", \"('P6_g_6 ', 'Amundsen')\", \"('P6_g_7 ', 'Monte Carlo')\", \"('P6_g_8 ', 'SODA')\", \"('P6_g_9 ', 'Big Eye')\", \"('P6_g_10 ', 'Data Band')\", \"('P6_g_11 ', 'Anomalo')\", \"('P6_g_l ', 'Metaplane')\", \"('P6_g_m ', 'Acceldata')\", \"('P6_h ', 'Em qual das opções abaixo você gasta a maior parte do seu tempo?')\", \"('P6_h_1 ', 'Desenvolvendo pipelines de dados utilizando linguagens de programação como Python, Scala, Java etc.')\", \"('P6_h_2 ', 'Realizando construções de ETL's em ferramentas como Pentaho, Talend, Dataflow etc.')\", \"('P6_h_3 ', 'Criando consultas através da linguagem SQL para exportar informações e compartilhar com as áreas de negócio.')\", \"('P6_h_4 ', 'Atuando na integração de diferentes fontes de dados através de plataformas proprietárias como Stitch Data, Fivetran etc.')\", \"('P6_h_5 ', 'Modelando soluções de arquitetura de dados, criando componentes de ingestão de dados, transformação e recuperação da informação.')\", \"('P6_h_6 ', 'Desenvolvendo/cuidando da manutenção de repositórios de dados baseados em streaming de eventos como Data Lakes e Data Lakehouses.')\", \"('P6_h_7 ', 'Atuando na modelagem dos dados, com o objetivo de criar conjuntos de dados como Data Warehouses, Data Marts etc.')\", \"('P6_h_8 ', 'Cuidando da qualidade dos dados, metadados e dicionário de dados.')\", \"('P6_h_9 ', 'Nenhuma das opções listadas refletem meu dia a dia.')\", \"('P7_1 ', 'Quais das opções abaixo fazem parte da sua rotina no trabalho atual com análise de dados?')\", \"('P7_a_1 ', 'Processo e analiso dados utilizando linguagens de programação como Python, R etc.')\", \"('P7_a_2 ', 'Realizo construções de dashboards em ferramentas de BI como PowerBI, Tableau, Looker, Qlik etc.')\", \"('P7_a_3 ', 'Crio consultas através da linguagem SQL para exportar informações e compartilhar com as áreas de negócio.')\", \"('P7_a_4 ', 'Utilizo API's para extrair dados e complementar minhas análises.')\", \"('P7_a_5 ', 'Realizo experimentos e estudos utilizando metodologias estatísticas como teste de hipótese, modelos de regressão etc.')\", \"('P7_a_6 ', 'Desenvolvo/cuido da manutenção de ETL's utilizando tecnologias como Talend, Pentaho, Airflow, Dataflow etc.')\", \"('P7_a_7 ', 'Atuo na modelagem dos dados, com o objetivo de criar conjuntos de dados, Data Warehouses, Data Marts etc.')\", \"('P7_a_8 ', 'Desenvolvo/cuido da manutenção de planilhas para atender as áreas de negócio.')\", \"('P7_a_9 ', 'Utilizo ferramentas avançadas de estatística como SAS')\", \"('P7_a_10 ', 'Nenhuma das opções listadas refletem meu dia a dia.')\", \"('P7_b ', 'Quais as ferramentas/tecnologias de ETL que você utiliza no trabalho como Data Analyst?')\", \"('P7_b_1 ', 'Scripts Python')\", \"('P7_b_2 ', 'SQL & Stored Procedures')\", \"('P7_b_3 ', 'Apache Airflow')\", \"('P7_b_4 ', 'Luigi')\", \"('P7_b_5 ', 'AWS Glue')\", \"('P7_b_6 ', 'Talend')\", \"('P7_b_7 ', 'Pentaho')\", \"('P7_b_8 ', 'Alteryx')\", \"('P7_b_9 ', 'Stitch')\", \"('P7_b_10 ', 'Fivetran')\", \"('P7_b_11 ', 'Google Dataflow')\", \"('P7_b_12 ', 'Oracle Data Integrator')\", \"('P7_b_13 ', 'IBM DataStage')\", \"('P7_b_14 ', 'SAP BW ETL')\", \"('P7_b_15 ', 'SQL Server Integration Services (SSIS)')\", \"('P7_b_16 ', 'SAS Data Integration')\", \"('P7_b_17 ', 'Qlik Sense')\", \"('P7_b_18 ', 'Knime')\", \"('P7_b_19 ', 'Databricks')\", \"('P7_b_20 ', 'Não utilizo ferramentas de ETL')\", \"('P7_c ', 'Sua empresa utiliza alguma das ferramentas listadas para dar mais autonomia em análise de dados para as áreas de negócio?')\", \"('P7_c_1 ', 'Ferramentas de AutoML como H2O.ai, Data Robot, BigML etc.')\", '(\\'P7_c_2 \\', \\'\"\"Point and Click\"\" Analytics como Alteryx, Knime, Rapidminer etc.\\')', \"('P7_c_3 ', 'Product metricts & Insights como Mixpanel, Amplitude, Adobe Analytics.')\", \"('P7_c_4 ', 'Ferramentas de análise dentro de ferramentas de CRM como Salesforce Einstein Anaytics ou Zendesk dashboards.')\", \"('P7_c_5 ', 'Minha empresa não utiliza essas ferramentas.')\", \"('P7_c_6 ', 'Não sei informar.')\", \"('P7_d ', 'Em qual das opções abaixo você gasta a maior parte do seu tempo de trabalho?')\", \"('P7_d_1 ', 'Processando e analisando dados utilizando linguagens de programação como Python, R etc.')\", \"('P7_d_2 ', 'Realizando construções de dashboards em ferramentas de BI como PowerBI, Tableau, Looker, Qlik etc.')\", \"('P7_d_3 ', 'Criando consultas através da linguagem SQL para exportar informações e compartilhar com as áreas de negócio.')\", \"('P7_d_4 ', 'Utilizando API's para extrair dados e complementar minhas análises.')\", \"('P7_d_5 ', 'Realizando experimentos e estudos utilizando metodologias estatísticas como teste de hipótese, modelos de regressão etc.')\", \"('P7_d_6 ', 'Desenvolvendo/cuidando da manutenção de ETL's utilizando tecnologias como Talend, Pentaho, Airflow, Dataflow etc.')\", \"('P7_d_7 ', 'Atuando na modelagem dos dados, com o objetivo de criar conjuntos de dados, Data Warehouses, Data Marts etc.')\", \"('P7_d_8 ', 'Desenvolvendo/cuidando da manutenção de planilhas do Excel ou Google Sheets para atender as áreas de negócio.')\", \"('P7_d_9 ', 'Utilizando ferramentas avançadas de estatística como SAS, SPSS, Stata etc, para realizar análises.')\", \"('P7_d_10 ', 'Nenhuma das opções listadas refletem meu dia a dia.')\", \"('P8_a ', 'Quais das opções abaixo fazem parte da sua rotina no trabalho atual com ciência de dados?')\", \"('P8_a_1 ', 'Estudos Ad-hoc com o objetivo de confirmar hipóteses, realizar modelos preditivos, forecasts, análise de cluster para resolver problemas pontuais e responder perguntas das áreas de negócio.')\", \"('P8_a_2 ', 'Sou responsável pela coleta e limpeza dos dados que uso para análise e modelagem.')\", \"('P8_a_3 ', 'Sou responsável por entrar em contato com os times de negócio para definição do problema, identificar a solução e apresentação de resultados.')\", \"('P8_a_4 ', 'Desenvolvo modelos de Machine Learning com o objetivo de colocar em produção em sistemas (produtos de dados).')\", \"('P8_a_5 ', 'Sou responsável por colocar modelos em produção, criar os pipelines de dados, APIs de consumo e monitoramento.')\", \"('P8_a_6 ', 'Cuido da manutenção de modelos de Machine Learning já em produção, atuando no monitoramento, ajustes e refatoração quando necessário.')\", \"('P8_a_7 ', 'Realizo construções de dashboards em ferramentas de BI como PowerBI, Tableau, Looker, Qlik, etc')\", \"('P8_a_8 ', 'Utilizo ferramentas avançadas de estatística como SAS, SPSS, Stata etc, para realizar análises estatísticas e ajustar modelos.Crio e dou manutenção em ETLs, DAGs e automações de pipelines de dados.')\", \"('P8_a_9 ', 'Crio e dou manutenção em ETLs, DAGs e automações de pipelines de dados.')\", \"('P8_a_10 ', 'Crio e gerencio soluções de Feature Store e cultura de MLOps.')\", \"('P8_a_11 ', 'Sou responsável por criar e manter a infra que meus modelos e soluções rodam (clusters, servidores, API, containers, etc.)')\", \"('P8_b ', 'Quais as técnicas e métodos listados abaixo você costuma utilizar no trabalho?')\", \"('P8_b_1 ', 'Utilizo modelos de regressão (linear, logística, GLM)')\", \"('P8_b_2 ', 'Utilizo redes neurais ou modelos baseados em árvore para criar modelos de classificação')\", \"('P8_b_3 ', 'Desenvolvo sistemas de recomendação (RecSys)')\", \"('P8_b_4 ', 'Utilizo métodos estatísticos Bayesianos para analisar dados')\", \"('P8_b_5 ', 'Utilizo técnicas de NLP (Natural Language Processing) para análisar dados não-estruturados')\", \"('P8_b_6 ', 'Utilizo métodos estatísticos clássicos (Testes de hipótese, análise multivariada, sobrevivência, dados longitudinais, inferência estatistica) para analisar dados')\", \"('P8_b_7 ', 'Utilizo cadeias de Markov ou HMM's para realizar análises de dados')\", \"('P8_b_8 ', 'Desenvolvo técnicas de Clusterização (K-means, Spectral, DBScan etc)')\", \"('P8_b_9 ', 'Realizo previsões através de modelos de Séries Temporais (Time Series)')\", \"('P8_b_10 ', 'Utilizo modelos de Reinforcement Learning (aprendizado por reforço)')\", \"('P8_b_11 ', 'Utilizo modelos de Machine Learning para detecção de fraude')\", \"('P8_b_l ', 'Utilizo métodos de Visão Computacional')\", \"('P8_b_m ', 'Utilizo modelos de Detecção de Churn')\", \"('P8_3 ', 'Quais dessas tecnologias fazem parte do seu dia a dia como cientista de dados?')\", \"('P8_c_1 ', 'Ferramentas de BI (PowerBI, Looker, Tableau, Qlik etc)')\", \"('P8_c_2 ', 'Planilhas (Excel, Google Sheets etc)')\", \"('P8_c_3 ', 'Ambientes de desenvolvimento local (R-studio, JupyterLab, Anaconda)')\", \"('P8_c_4 ', 'Ambientes de desenvolvimento na nuvem (Google Colab, AWS Sagemaker, Kaggle Notebooks etc)')\", \"('P8_c_5 ', 'Ferramentas de AutoML (Datarobot, H2O, Auto-Keras etc)')\", \"('P8_c_6 ', 'Ferramentas de ETL (Apache Airflow, NiFi, Stitch, Fivetran, Pentaho etc)')\", \"('P8_c_7 ', 'Plataformas de Machine Learning (TensorFlow, Azure Machine Learning, Kubeflow etc)')\", \"('P8_c_8 ', 'Feature Store (Feast, Hopsworks, AWS Feature Store, Databricks Feature Store etc)')\", \"('P8_c_9 ', 'Sistemas de controle de versão (Github, DVC, Neptune, Gitlab etc)')\", \"('P8_c_10 ', 'Plataformas de Data Apps (Streamlit, Shiny, Plotly Dash etc)')\", \"('P8_c_11 ', 'Ferramentas de estatística avançada como SPSS, SAS, etc.')\", \"('P8_d ', 'Em qual das opções abaixo você gasta a maior parte do seu tempo no trabalho?')\", \"('P8_d_1 ', 'Estudos Ad-hoc com o objetivo de confirmar hipóteses, realizar modelos preditivos, forecasts, análise de cluster para resolver problemas pontuais e responder perguntas das áreas de negócio.')\", \"('P8_d_2 ', 'Coletando e limpando os dados que uso para análise e modelagem.')\", \"('P8_d_3 ', 'Entrando em contato com os times de negócio para definição do problema, identificar a solução e apresentação de resultados.')\", \"('P8_d_4 ', 'Desenvolvendo modelos de Machine Learning com o objetivo de colocar em produção em sistemas (produtos de dados).')\", \"('P8_d_5 ', 'Colocando modelos em produção, criando os pipelines de dados, APIs de consumo e monitoramento.')\", \"('P8_d_6 ', 'Cuidando da manutenção de modelos de Machine Learning já em produção, atuando no monitoramento, ajustes e refatoração quando necessário.')\", \"('P8_d_7 ', 'Realizando construções de dashboards em ferramentas de BI como PowerBI, Tableau, Looker, Qlik, etc.')\", \"('P8_d_8 ', 'Utilizando ferramentas avançadas de estatística como SAS, SPSS, Stata etc, para realizar análises.')\", \"('P8_d_9 ', 'Criando e dando manutenção em ETLs, DAGs e automações de pipelines de dados.')\", \"('P8_d_10 ', 'Criando e gerenciando soluções de Feature Store e cultura de MLOps.')\", \"('P8_d_11 ', 'Criando e mantendo a infra que meus modelos e soluções rodam (clusters, servidores, API, containers, etc.)')\", 'salario_medio_mensal', 'grupo_cargo', 'experiencia_anos_num', 'ano']\n"
     ]
    }
   ],
   "source": [
    "print(df_2022_kaggle.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "014eaad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "357"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_2022_kaggle.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87f9d0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapa_renomeacao_2022 = {\n",
    "  # === Colunas que você já mapeou (mantidas e validadas) ===\n",
    "  'id_participante': 'id_participante', 'idade': 'idade', 'faixa_idade': 'faixa_idade', 'genero': 'genero', 'etnia': 'etnia', 'pcd': 'pcd', 'experiencia_prejudicada': 'experiencia_prejudicada', 'uf_residencia': 'uf_residencia', 'regiao_residencia': 'regiao_residencia', 'regiao_origem': 'regiao_origem', 'nivel_ensino': 'nivel_ensino', 'area_formacao': 'area_formacao', 'situacao_trabalho': 'situacao_trabalho', 'setor_atuacao': 'setor_atuacao', 'tamanho_empresa': 'tamanho_empresa', 'atua_como_gestor': 'atua_como_gestor', 'cargo_atual': 'cargo_atual', 'nivel_hierarquico': 'nivel_hierarquico', 'faixa_salarial': 'faixa_salarial', 'experiencia_dados_anos': 'experiencia_dados_anos', 'experiencia_ti_anos': 'experiencia_ti_anos', 'satisfacao_trabalho': 'satisfacao_trabalho', 'motivos_insatisfacao': 'motivos_insatisfacao', 'entrevistas_ultimos_6m': 'entrevistas_ultimos_6m', 'planos_mudar_emprego': 'planos_mudar_emprego', 'criterios_escolha_emprego': 'criterios_escolha_emprego', 'modelo_trabalho_atual': 'modelo_trabalho_atual', 'modelo_trabalho_ideal': 'modelo_trabalho_ideal', 'empresa_teve_layoff_2022': 'empresa_teve_layoff', 'tamanho_equipe_dados': 'tamanho_equipe_dados', 'desafios_gestor': 'desafios_gestor', 'linguagens_usadas_dia_a_dia': 'linguagens_usadas_dia_a_dia', 'linguagem_principal': 'linguagem_principal', 'linguagem_preferida': 'linguagem_preferida', 'bancos_dados_usados_dia_a_dia': 'bancos_dados_usados_dia_a_dia', 'clouds_utilizadas': 'clouds_utilizadas', 'cloud_preferida': 'cloud_preferida', 'ferramentas_bi_usadas_dia_a_dia': 'ferramentas_bi_usadas_dia_a_dia', 'tipo_oportunidade_buscada': 'tipo_oportunidade_buscada', 'tempo_busca_emprego_meses': 'tempo_busca_emprego_meses',\n",
    "  \n",
    "  # === NOVAS COLUNAS MAPEADAS (COMPLEMENTO) ===\n",
    "  \n",
    "  # --- Tema: Experiência Profissional e Demografia ---\n",
    "  \"('P1_f ', 'aspectos_prejudicados')\": 'prejudicado_aspectos_lista',\n",
    "  \"('P1_g ', 'vive_no_brasil')\": 'vive_no_brasil',\n",
    "  \"('P1_i ', 'Estado onde mora')\": 'estado_residencia',\n",
    "  \"('P1_j ', 'Mudou de Estado?')\": 'mudou_de_estado',\n",
    "\n",
    "  # --- Tema: Detalhes do Trabalho ---\n",
    "  \"('P2_e ', 'Cargo como Gestor')\": 'cargo_gestor',\n",
    "  \"('P2_r ', 'Caso sua empresa decida pelo modelo 100% presencial qual será sua atitude?')\": 'atitude_retorno_presencial',\n",
    "\n",
    "  # --- Tema: Motivos de Insatisfação e Critérios de Escolha ---\n",
    "  \"('P2_l_1 ', 'Falta de oportunidade de crescimento no emprego atual')\": 'insatisfacao_fator_falta_crescimento',\n",
    "  \"('P2_l_2 ', 'Salário atual não corresponde ao mercado')\": 'insatisfacao_fator_salario_defasado',\n",
    "  \"('P2_l_3 ', 'Não tenho uma boa relação com meu líder/gestor')\": 'insatisfacao_fator_relacao_gestor',\n",
    "  \"('P2_l_4 ', 'Gostaria de trabalhar em em outra área de atuação')\": 'insatisfacao_fator_desejo_mudar_area',\n",
    "  \"('P2_l_5 ', 'Gostaria de receber mais benefícios')\": 'insatisfacao_fator_beneficios',\n",
    "  \"('P2_l_6 ', 'O clima de trabalho/ambiente não é bom')\": 'insatisfacao_fator_ambiente_ruim',\n",
    "  \"('P2_l_7 ', 'Falta de maturidade analítica na empresa')\": 'insatisfacao_fator_baixa_maturidade_empresa',\n",
    "  \"('P2_o_1 ', 'Remuneração/Salário')\": 'criterio_escolha_remuneracao',\n",
    "  \"('P2_o_2 ', 'Benefícios')\": 'criterio_escolha_beneficios',\n",
    "  \"('P2_o_3 ', 'Propósito do trabalho e da empresa')\": 'criterio_escolha_proposito',\n",
    "  \"('P2_o_4 ', 'Flexibilidade de trabalho remoto')\": 'criterio_escolha_flexibilidade',\n",
    "  \"('P2_o_5 ', 'Ambiente e clima de trabalho')\": 'criterio_escolha_ambiente',\n",
    "  \"('P2_o_6 ', 'Oportunidade de aprendizado e trabalhar com referências na área')\": 'criterio_escolha_aprendizado',\n",
    "  \"('P2_o_7 ', 'Plano de carreira e oportunidades de crescimento profissional')\": 'criterio_escolha_plano_carreira',\n",
    "  \"('P2_o_8 ', 'Maturidade da empresa em termos de tecnologia e dados')\": 'criterio_escolha_maturidade_empresa',\n",
    "  \"('P2_o_9 ', 'Qualidade dos gestores e líderes')\": 'criterio_escolha_qualidade_gestores',\n",
    "  \"('P2_o_10 ', 'Reputação que a empresa tem no mercado')\": 'criterio_escolha_reputacao_empresa',\n",
    "\n",
    "  # --- Tema: Detalhes da Equipe de Dados e Gestão ---\n",
    "  \"('P3_b ', 'Quais desses papéis/cargos fazem parte do time (ou chapter) de dados da sua empresa?')\": 'empresa_cargos_dados_lista',\n",
    "  \"('P3_b_1 ', 'Analytics Engineer')\": 'empresa_tem_analytics_engineer',\n",
    "  \"('P3_b_2 ', 'Engenharia de Dados/Data Engineer')\": 'empresa_tem_engenheiro_dados',\n",
    "  \"('P3_b_3 ', 'Analista de Dados/Data Analyst')\": 'empresa_tem_analista_dados',\n",
    "  \"('P3_b_4 ', 'Cientista de Dados/Data Scientist')\": 'empresa_tem_cientista_dados',\n",
    "  \"('P3_b_5 ', 'Database Administrator/DBA')\": 'empresa_tem_dba',\n",
    "  \"('P3_b_6 ', 'Analista de Business Intelligence/BI')\": 'empresa_tem_analista_bi',\n",
    "  \"('P3_b_7 ', 'Arquiteto de Dados/Data Architect')\": 'empresa_tem_arquiteto_dados',\n",
    "  \"('P3_b_8 ', 'Data Product Manager/DPM')\": 'empresa_tem_dpm',\n",
    "  \"('P3_b_9 ', 'Business Analyst')\": 'empresa_tem_business_analyst',\n",
    "  \"('P3_c ', 'Quais dessas responsabilidades fazem parte da sua rotina atual de trabalho como gestor?')\": 'gestor_responsabilidades_lista',\n",
    "  \"('P3_c_1 ', 'Pensar na visão de longo prazo de dados da empresa e fortalecimento da cultura analítica da companhia.')\": 'gestor_resp_visao_longo_prazo',\n",
    "  \"('P3_c_2 ', 'Organização de treinamentos e iniciativas com o objetivo de aumentar a maturidade analítica das áreas de negócios.')\": 'gestor_resp_treinamentos',\n",
    "  \"('P3_c_3 ', 'Atração, seleção e contratação de talentos para o time de dados.')\": 'gestor_resp_contratacao',\n",
    "  \"('P3_c_4 ', 'Decisão sobre contratação de ferramentas e tecnologias relacionadas a dados.')\": 'gestor_resp_decisao_ferramentas',\n",
    "  \"('P3_c_5 ', 'Sou gestor da equipe responsável pela engenharia de dados e por manter o Data Lake da empresa como fonte única dos dados, garantindo a qualidade e confiabilidade da informação.')\": 'gestor_resp_head_engenharia',\n",
    "  \"('P3_c_6 ', 'Sou gestor da equipe responsável pela entrega de dados, estudos, relatórios e dashboards para as áreas de negócio da empresa.')\": 'gestor_resp_head_analise_bi',\n",
    "  \"('P3_c_7 ', 'Sou gestor da equipe responsável por iniciativas e projetos envolvendo Inteligência Artificial e Machine Learning.')\": 'gestor_resp_head_ia_ml',\n",
    "  \"('P3_c_8 ', 'Apesar de ser gestor ainda atuo na parte técnica, construindo soluções/análises/modelos etc.')\": 'gestor_resp_atua_tecnico',\n",
    "  \"('P3_c_9 ', 'Gestão de projetos de dados, cuidando das etapas, equipes envolvidas, atingimento dos objetivos etc.')\": 'gestor_resp_gestao_projetos',\n",
    "  \"('P3_c_10 ', 'Gestão de produtos de dados, cuidando da visão dos produtos, backlog, feedback de usuários etc.')\": 'gestor_resp_gestao_produtos',\n",
    "  \"('P3_c_11 ', 'Gestão de pessoas, apoio no desenvolvimento das pessoas, evolução de carreira')\": 'gestor_resp_gestao_pessoas',\n",
    "  \"('P3_d_1 ', 'a Contratar novos talentos.')\": 'gestor_desafio_contratar_talentos',\n",
    "  \"('P3_d_2 ', 'b Reter talentos.')\": 'gestor_desafio_reter_talentos',\n",
    "  \"('P3_d_3 ', 'c Convencer a empresa a aumentar os investimentos na área de dados.')\": 'gestor_desafio_obter_investimento',\n",
    "  \"('P3_d_4 ', 'd Gestão de equipes no ambiente remoto.')\": 'gestor_desafio_gestao_remota',\n",
    "  \"('P3_d_5 ', 'e Gestão de projetos envolvendo áreas multidisciplinares da empresa.')\": 'gestor_desafio_projetos_multiarea',\n",
    "  \"('P3_d_6 ', 'f Organizar as informações e garantir a qualidade e confiabilidade.')\": 'gestor_desafio_qualidade_confiabilidade',\n",
    "  \"('P3_d_7 ', 'g Conseguir processar e armazenar um alto volume de dados.')\": 'gestor_desafio_volume_dados',\n",
    "  \"('P3_d_8 ', 'h Conseguir gerar valor para as áreas de negócios através de estudos e experimentos.')\": 'gestor_desafio_gerar_valor_negocio',\n",
    "  \"('P3_d_9 ', 'i Desenvolver e manter modelos Machine Learning em produção.')\": 'gestor_desafio_ml_em_producao',\n",
    "  \"('P3_d_10 ', 'j Gerenciar a expectativa das áreas de negócio em relação as entregas das equipes de dados.')\": 'gestor_desafio_gerenciar_expectativas',\n",
    "  \"('P3_d_11 ', 'k Garantir a manutenção dos projetos e modelos em produção, em meio ao crescimento da empresa.')\": 'gestor_desafio_manutencao_producao',\n",
    "  \"('P3_d_12 ', 'Conseguir levar inovação para a empresa através dos dados.')\": 'gestor_desafio_inovar',\n",
    "  \"('P3_d_13 ', 'Garantir retorno do investimento (ROI) em projetos de dados.')\": 'gestor_desafio_garantir_roi',\n",
    "  \"('P3_d_14 ', 'Dividir o tempo entre entregas técnicas e gestão.')\": 'gestor_desafio_dividir_tempo_tecnico_gestao',\n",
    "\n",
    "  # --- Tema: Ferramentas e Tecnologias (Detalhes) ---\n",
    "  \"('P4_a ', 'Mesmo que esse não seja seu cargo formal, você considera que sua atuação no dia a dia, reflete alguma das opções listadas abaixo?')\": 'atuacao_funcao',\n",
    "  \"('P4_a_1 ', 'Atuacao')\": 'atuacao_em_dados',\n",
    "  \"('P4_b ', 'Quais das fontes de dados listadas você já analisou ou processou no trabalho?')\": 'fontes_dados_lista',\n",
    "  \"('P4_b_1 ', 'Dados relacionais (estruturados em bancos SQL)')\": 'fonte_dados_usa_relacionais',\n",
    "  \"('P4_b_2 ', 'Dados armazenados em bancos NoSQL')\": 'fonte_dados_usa_nosql',\n",
    "  \"('P4_b_3 ', 'Imagens')\": 'fonte_dados_usa_imagens',\n",
    "  \"('P4_b_4 ', 'Textos/Documentos')\": 'fonte_dados_usa_textos',\n",
    "  \"('P4_b_5 ', 'Vídeos')\": 'fonte_dados_usa_videos',\n",
    "  \"('P4_b_6 ', 'Áudios')\": 'fonte_dados_usa_audios',\n",
    "  \"('P4_b_7 ', 'Planilhas')\": 'fonte_dados_usa_planilhas',\n",
    "  \"('P4_b_8 ', 'Dados georeferenciados')\": 'fonte_dados_usa_geo',\n",
    "  \"('P4_c ', 'Entre as fontes de dados listadas, quais você utiliza na maior parte do tempo?')\": 'fonte_dados_principal',\n",
    "  \"('P4_d_1 ', 'SQL')\": 'linguagem_usa_sql',\n",
    "  \"('P4_d_2 ', 'R ')\": 'linguagem_usa_r',\n",
    "  \"('P4_d_3 ', 'Python')\": 'linguagem_usa_python',\n",
    "  \"('P4_d_4 ', 'C/C++/C#')\": 'linguagem_usa_c_cplusplus_csharp',\n",
    "  \"('P4_d_5 ', '.NET')\": 'linguagem_usa_dotnet',\n",
    "  \"('P4_d_6 ', 'Java')\": 'linguagem_usa_java',\n",
    "  \"('P4_d_7 ', 'Julia')\": 'linguagem_usa_julia',\n",
    "  \"('P4_d_8 ', 'SAS/Stata')\": 'linguagem_usa_sas_stata',\n",
    "  \"('P4_d_9 ', 'Visual Basic/VBA')\": 'linguagem_usa_vba',\n",
    "  \"('P4_d_10 ', 'Scala')\": 'linguagem_usa_scala',\n",
    "  \"('P4_d_11 ', 'Matlab')\": 'linguagem_usa_matlab',\n",
    "  \"('P4_d_12 ', 'PHP')\": 'linguagem_usa_php',\n",
    "  \"('P4_d_13 ', 'Javascript')\": 'linguagem_usa_javascript',\n",
    "  \"('P4_d_14 ', 'Não utilizo nenhuma linguagem')\": 'linguagem_usa_nenhuma',\n",
    "  \"('P4_g_1 ', 'MySQL')\": 'banco_dados_usa_mysql',\n",
    "  \"('P4_g_2 ', 'Oracle')\": 'banco_dados_usa_oracle',\n",
    "  \"('P4_g_3 ', 'SQL SERVER')\": 'banco_dados_usa_sql_server',\n",
    "  \"('P4_f_4 ', 'Amazon Aurora ou RDS')\": 'banco_dados_usa_aurora_rds', # Corrigindo inconsistência no nome original\n",
    "  \"('P4_f_5 ', 'DynamoDB')\": 'banco_dados_usa_dynamodb',\n",
    "  \"('P4_f_6 ', 'CoachDB')\": 'banco_dados_usa_coachdb',\n",
    "  \"('P4_f_7 ', 'Cassandra')\": 'banco_dados_usa_cassandra',\n",
    "  \"('P4_f_8 ', 'MongoDB')\": 'banco_dados_usa_mongodb',\n",
    "  \"('P4_f_9 ', 'MariaDB')\": 'banco_dados_usa_mariadb',\n",
    "  \"('P4_f_10 ', 'Datomic')\": 'banco_dados_usa_datomic',\n",
    "  \"('P4_f_11 ', 'S3')\": 'banco_dados_usa_s3',\n",
    "  \"('P4_f_12 ', 'PostgreSQL')\": 'banco_dados_usa_postgresql',\n",
    "  \"('P4_f_13 ', 'ElasticSearch')\": 'banco_dados_usa_elasticsearch',\n",
    "  \"('P4_f_14 ', 'DB2')\": 'banco_dados_usa_db2',\n",
    "  \"('P4_f_15 ', 'Microsoft Access')\": 'banco_dados_usa_access',\n",
    "  \"('P4_f_16 ', 'SQLite')\": 'banco_dados_usa_sqlite',\n",
    "  \"('P4_f_17 ', 'Sybase')\": 'banco_dados_usa_sybase',\n",
    "  \"('P4_f_18 ', 'Firebase')\": 'banco_dados_usa_firebase',\n",
    "  \"('P4_f_19 ', 'Vertica')\": 'banco_dados_usa_vertica',\n",
    "  \"('P4_f_20 ', 'Redis')\": 'banco_dados_usa_redis',\n",
    "  \"('P4_f_21 ', 'Neo4J')\": 'banco_dados_usa_neo4j',\n",
    "  \"('P4_f_22 ', 'Google BigQuery')\": 'banco_dados_usa_bigquery',\n",
    "  \"('P4_f_23 ', 'Google Firestore')\": 'banco_dados_usa_firestore',\n",
    "  \"('P4_f_24 ', 'Amazon Redshift')\": 'banco_dados_usa_redshift',\n",
    "  \"('P4_f_25 ', 'Amazon Athena')\": 'banco_dados_usa_athena',\n",
    "  \"('P4_f_26 ', 'Snowflake')\": 'banco_dados_usa_snowflake',\n",
    "  \"('P4_f_27 ', 'Databricks')\": 'banco_dados_usa_databricks',\n",
    "  \"('P4_f_28 ', 'HBase')\": 'banco_dados_usa_hbase',\n",
    "  \"('P4_f_29 ', 'Presto')\": 'banco_dados_usa_presto',\n",
    "  \"('P4_f_30 ', 'Splunk')\": 'banco_dados_usa_splunk',\n",
    "  \"('P4_f_31 ', 'SAP HANA')\": 'banco_dados_usa_sap_hana',\n",
    "  \"('P4_f_32 ', 'Hive')\": 'banco_dados_usa_hive',\n",
    "  \"('P4_f_33 ', 'Firebird')\": 'banco_dados_usa_firebird',\n",
    "  \"('P4_h_1 ', 'Azure (Microsoft)')\": 'cloud_usa_azure',\n",
    "  \"('P4_h_2 ', 'Amazon Web Services (AWS)')\": 'cloud_usa_aws',\n",
    "  \"('P4_h_3 ', 'Google Cloud (GCP)')\": 'cloud_usa_gcp',\n",
    "  \"('P4_i_1 ', 'Microsoft PowerBI')\": 'bi_usa_powerbi',\n",
    "  \"('P4_i_2 ', 'Qlik View/Qlik Sense')\": 'bi_usa_qlik',\n",
    "  \"('P4_i_3 ', 'Tableau')\": 'bi_usa_tableau',\n",
    "  \"('P4_i_4 ', 'Metabase')\": 'bi_usa_metabase',\n",
    "  \"('P4_i_5 ', 'Superset')\": 'bi_usa_superset',\n",
    "  \"('P4_i_6 ', 'Redash')\": 'bi_usa_redash',\n",
    "  \"('P4_i_7 ', 'MicroStrategy')\": 'bi_usa_microstrategy',\n",
    "  \"('P4_i_8 ', 'IBM Analytics/Cognos')\": 'bi_usa_ibm_cognos',\n",
    "  \"('P4_i_9 ', 'SAP Business Objects')\": 'bi_usa_sap_bi',\n",
    "  \"('P4_i_10 ', 'Oracle Business Intelligence')\": 'bi_usa_oracle_bi',\n",
    "  \"('P4_i_11 ', 'Amazon QuickSight')\": 'bi_usa_quicksight',\n",
    "  \"('P4_i_12 ', 'Salesforce/Einstein Analytics')\": 'bi_usa_salesforce_einstein',\n",
    "  \"('P4_i_13 ', 'Mode')\": 'bi_usa_mode',\n",
    "  \"('P4_i_14 ', 'Alteryx')\": 'bi_usa_alteryx',\n",
    "  \"('P4_i_15 ', 'Birst')\": 'bi_usa_birst',\n",
    "  \"('P4_i_16 ', 'Looker')\": 'bi_usa_looker',\n",
    "  \"('P4_i_17 ', 'Google Data Studio')\": 'bi_usa_google_data_studio',\n",
    "  \"('P4_i_18 ', 'SAS Visual Analytics')\": 'bi_usa_sas_va',\n",
    "  \"('P4_i_19 ', 'Grafana')\": 'bi_usa_grafana',\n",
    "  \"('P4_i_20 ', 'TIBCO Spotfire')\": 'bi_usa_tibco',\n",
    "  \"('P4_i_21 ', 'Pentaho')\": 'bi_usa_pentaho',\n",
    "  \"('P4_i_22 ', 'Fazemos todas as análises utilizando apenas Excel ou planilhas do google')\": 'bi_usa_excel_gsheets',\n",
    "  \"('P4_i_23 ', 'Não utilizo nenhuma ferramenta de BI no trabalho')\": 'bi_usa_nenhuma',\n",
    "  \n",
    "  # --- Tema: Detalhes sobre Carreiras Específicas ---\n",
    "  \"('P5_a ', 'Qual seu objetivo na área de dados?')\": 'objetivo_profissional',\n",
    "  \"('P5_d ', 'Como tem sido a busca por um emprego na área de dados?')\": 'carreira_experiencia_processos_seletivos',\n",
    "  \"('P6_a ', 'Quais das opções abaixo fazem parte da sua rotina no trabalho atual como engenheiro de dados?')\": 'de_rotina_lista',\n",
    "  \"('P6_a_1 ', 'Desenvolvo pipelines de dados utilizando linguagens de programação como Python, Scala, Java etc.')\": 'de_rotina_pipeline_codigo',\n",
    "  \"('P6_a_2 ', 'Realizo construções de ETL's em ferramentas como Pentaho, Talend, Dataflow etc.')\": 'de_rotina_etl_ferramentas',\n",
    "  \"('P6_a_3 ', 'Crio consultas através da linguagem SQL para exportar informações e compartilhar com as áreas de negócio.')\": 'de_rotina_consultas_sql',\n",
    "  \"('P6_a_4 ', 'Atuo na integração de diferentes fontes de dados através de plataformas proprietárias como Stitch Data, Fivetran etc.')\": 'de_rotina_integracao_plataformas',\n",
    "  \"('P6_a_5 ', 'Modelo soluções de arquitetura de dados, criando componentes de ingestão de dados, transformação e recuperação da informação.')\": 'de_rotina_modelagem_arquitetura',\n",
    "  \"('P6_a_6 ', 'Desenvolvo/cuido da manutenção de repositórios de dados baseados em streaming de eventos como Data Lakes e Data Lakehouses.')\": 'de_rotina_manutencao_datalakes',\n",
    "  \"('P6_a_7 ', 'Atuo na modelagem dos dados, com o objetivo de criar conjuntos de dados como Data Warehouses, Data Marts etc.')\": 'de_rotina_modelagem_dados',\n",
    "  \"('P6_a_8 ', 'Cuido da qualidade dos dados, metadados e dicionário de dados.')\": 'de_rotina_qualidade_dados',\n",
    "  \"('P6_a_9 ', 'Nenhuma das opções listadas refletem meu dia a dia.')\": 'de_rotina_nenhuma_das_opcoes',\n",
    "  \"('P6_b ', 'Quais as ferramentas/tecnologias de ETL que você utiliza no trabalho como Data Engineer?')\": 'de_ferramentas_etl_lista',\n",
    "  \"('P6_c ', 'Sua organização possui um Data Lake?')\": 'de_empresa_possui_data_lake',\n",
    "  \"('P6_d ', 'Qual tecnologia utilizada como plataforma do Data Lake?')\": 'de_empresa_tecnologia_data_lake',\n",
    "  \"('P6_e ', 'Sua organização possui um Data Warehouse?')\": 'de_empresa_possui_data_warehouse',\n",
    "  \"('P6_f ', 'Qual tecnologia utilizada como plataforma do Data Warehouse?')\": 'de_empresa_tecnologia_data_warehouse',\n",
    "  \"('P6_g ', 'Quais as ferramentas de gestão de Qualidade de dados, Metadados e catálogo de dados você utiliza no trabalho?')\": 'de_ferramentas_qualidade_dados_lista',\n",
    "  \"('P6_h ', 'Em qual das opções abaixo você gasta a maior parte do seu tempo?')\": 'de_maior_tempo_gasto',\n",
    "  \"('P7_1 ', 'Quais das opções abaixo fazem parte da sua rotina no trabalho atual com análise de dados?')\": 'da_rotina_lista',\n",
    "  \"('P7_a_1 ', 'Processo e analiso dados utilizando linguagens de programação como Python, R etc.')\": 'da_rotina_analise_codigo',\n",
    "  \"('P7_a_2 ', 'Realizo construções de dashboards em ferramentas de BI como PowerBI, Tableau, Looker, Qlik etc.')\": 'da_rotina_dashboards_bi',\n",
    "  \"('P7_a_3 ', 'Crio consultas através da linguagem SQL para exportar informações e compartilhar com as áreas de negócio.')\": 'da_rotina_consultas_sql',\n",
    "  \"('P7_a_4 ', 'Utilizo API's para extrair dados e complementar minhas análises.')\": 'da_rotina_extracao_api',\n",
    "  \"('P7_a_5 ', 'Realizo experimentos e estudos utilizando metodologias estatísticas como teste de hipótese, modelos de regressão etc.')\": 'da_rotina_estatistica_testes',\n",
    "  \"('P7_a_6 ', 'Desenvolvo/cuido da manutenção de ETL's utilizando tecnologias como Talend, Pentaho, Airflow, Dataflow etc.')\": 'da_rotina_manutencao_etl',\n",
    "  \"('P7_a_7 ', 'Atuo na modelagem dos dados, com o objetivo de criar conjuntos de dados, Data Warehouses, Data Marts etc.')\": 'da_rotina_modelagem_dados',\n",
    "  \"('P7_a_8 ', 'Desenvolvo/cuido da manutenção de planilhas para atender as áreas de negócio.')\": 'da_rotina_manutencao_planilhas',\n",
    "  \"('P7_a_9 ', 'Utilizo ferramentas avançadas de estatística como SAS')\": 'da_rotina_estatistica_avancada',\n",
    "  \"('P7_a_10 ', 'Nenhuma das opções listadas refletem meu dia a dia.')\": 'da_rotina_nenhuma_das_opcoes',\n",
    "  \"('P7_b ', 'Quais as ferramentas/tecnologias de ETL que você utiliza no trabalho como Data Analyst?')\": 'da_ferramentas_etl_lista',\n",
    "  \"('P7_c ', 'Sua empresa utiliza alguma das ferramentas listadas para dar mais autonomia em análise de dados para as áreas de negócio?')\": 'da_ferramentas_autonomia_negocios_lista',\n",
    "  \"('P7_d ', 'Em qual das opções abaixo você gasta a maior parte do seu tempo de trabalho?')\": 'da_maior_tempo_gasto',\n",
    "  \"('P8_a ', 'Quais das opções abaixo fazem parte da sua rotina no trabalho atual com ciência de dados?')\": 'ds_rotina_lista',\n",
    "  \"('P8_a_1 ', 'Estudos Ad-hoc com o objetivo de confirmar hipóteses, realizar modelos preditivos, forecasts, análise de cluster para resolver problemas pontuais e responder perguntas das áreas de negócio.')\": 'ds_rotina_estudos_ad_hoc',\n",
    "  \"('P8_a_2 ', 'Sou responsável pela coleta e limpeza dos dados que uso para análise e modelagem.')\": 'ds_rotina_coleta_limpeza',\n",
    "  \"('P8_a_3 ', 'Sou responsável por entrar em contato com os times de negócio para definição do problema, identificar a solução e apresentação de resultados.')\": 'ds_rotina_contato_negocios',\n",
    "  \"('P8_a_4 ', 'Desenvolvo modelos de Machine Learning com o objetivo de colocar em produção em sistemas (produtos de dados).')\": 'ds_rotina_desenvolvimento_ml',\n",
    "  \"('P8_a_5 ', 'Sou responsável por colocar modelos em produção, criar os pipelines de dados, APIs de consumo e monitoramento.')\": 'ds_rotina_ml_em_producao',\n",
    "  \"('P8_a_6 ', 'Cuido da manutenção de modelos de Machine Learning já em produção, atuando no monitoramento, ajustes e refatoração quando necessário.')\": 'ds_rotina_manutencao_ml',\n",
    "  \"('P8_a_7 ', 'Realizo construções de dashboards em ferramentas de BI como PowerBI, Tableau, Looker, Qlik, etc')\": 'ds_rotina_dashboards_bi',\n",
    "  \"('P8_a_8 ', 'Utilizo ferramentas avançadas de estatística como SAS, SPSS, Stata etc, para realizar análises estatísticas e ajustar modelos.Crio e dou manutenção em ETLs, DAGs e automações de pipelines de dados.')\": 'ds_rotina_estatistica_avancada',\n",
    "  \"('P8_a_9 ', 'Crio e dou manutenção em ETLs, DAGs e automações de pipelines de dados.')\": 'ds_rotina_manutencao_etl',\n",
    "  \"('P8_a_10 ', 'Crio e gerencio soluções de Feature Store e cultura de MLOps.')\": 'ds_rotina_feature_store_mlops',\n",
    "  \"('P8_a_11 ', 'Sou responsável por criar e manter a infra que meus modelos e soluções rodam (clusters, servidores, API, containers, etc.)')\": 'ds_rotina_infraestrutura',\n",
    "  \"('P8_b ', 'Quais as técnicas e métodos listados abaixo você costuma utilizar no trabalho?')\": 'ds_tecnicas_lista',\n",
    "  \"('P8_b_1 ', 'Utilizo modelos de regressão (linear, logística, GLM)')\": 'ds_tecnica_regressao',\n",
    "  \"('P8_b_2 ', 'Utilizo redes neurais ou modelos baseados em árvore para criar modelos de classificação')\": 'ds_tecnica_classificacao_arvores_redes',\n",
    "  \"('P8_b_3 ', 'Desenvolvo sistemas de recomendação (RecSys)')\": 'ds_tecnica_sistemas_recomendacao',\n",
    "  \"('P8_b_4 ', 'Utilizo métodos estatísticos Bayesianos para analisar dados')\": 'ds_tecnica_estatistica_bayesiana',\n",
    "  \"('P8_b_5 ', 'Utilizo técnicas de NLP (Natural Language Processing) para análisar dados não-estruturados')\": 'ds_tecnica_nlp',\n",
    "  \"('P8_b_6 ', 'Utilizo métodos estatísticos clássicos (Testes de hipótese, análise multivariada, sobrevivência, dados longitudinais, inferência estatistica) para analisar dados')\": 'ds_tecnica_estatistica_classica',\n",
    "  \"('P8_b_7 ', 'Utilizo cadeias de Markov ou HMM's para realizar análises de dados')\": 'ds_tecnica_markov_hmm',\n",
    "  \"('P8_b_8 ', 'Desenvolvo técnicas de Clusterização (K-means, Spectral, DBScan etc)')\": 'ds_tecnica_clusterizacao',\n",
    "  \"('P8_b_9 ', 'Realizo previsões através de modelos de Séries Temporais (Time Series)')\": 'ds_tecnica_series_temporais',\n",
    "  \"('P8_b_10 ', 'Utilizo modelos de Reinforcement Learning (aprendizado por reforço)')\": 'ds_tecnica_reinforcement_learning',\n",
    "  \"('P8_b_11 ', 'Utilizo modelos de Machine Learning para detecção de fraude')\": 'ds_tecnica_deteccao_fraude',\n",
    "  \"('P8_b_l ', 'Utilizo métodos de Visão Computacional')\": 'ds_tecnica_visao_computacional',\n",
    "  \"('P8_b_m ', 'Utilizo modelos de Detecção de Churn')\": 'ds_tecnica_deteccao_churn',\n",
    "  \"('P8_3 ', 'Quais dessas tecnologias fazem parte do seu dia a dia como cientista de dados?')\": 'ds_tecnologias_lista',\n",
    "  \"('P8_c_1 ', 'Ferramentas de BI (PowerBI, Looker, Tableau, Qlik etc)')\": 'ds_tecnologia_ferramentas_bi',\n",
    "  \"('P8_c_2 ', 'Planilhas (Excel, Google Sheets etc)')\": 'ds_tecnologia_planilhas',\n",
    "  \"('P8_c_3 ', 'Ambientes de desenvolvimento local (R-studio, JupyterLab, Anaconda)')\": 'ds_tecnologia_dev_local',\n",
    "  \"('P8_c_4 ', 'Ambientes de desenvolvimento na nuvem (Google Colab, AWS Sagemaker, Kaggle Notebooks etc)')\": 'ds_tecnologia_dev_nuvem',\n",
    "  \"('P8_c_5 ', 'Ferramentas de AutoML (Datarobot, H2O, Auto-Keras etc)')\": 'ds_tecnologia_automl',\n",
    "  \"('P8_c_6 ', 'Ferramentas de ETL (Apache Airflow, NiFi, Stitch, Fivetran, Pentaho etc)')\": 'ds_tecnologia_etl',\n",
    "  \"('P8_c_7 ', 'Plataformas de Machine Learning (TensorFlow, Azure Machine Learning, Kubeflow etc)')\": 'ds_tecnologia_plataformas_ml',\n",
    "  \"('P8_c_8 ', 'Feature Store (Feast, Hopsworks, AWS Feature Store, Databricks Feature Store etc)')\": 'ds_tecnologia_feature_store',\n",
    "  \"('P8_c_9 ', 'Sistemas de controle de versão (Github, DVC, Neptune, Gitlab etc)')\": 'ds_tecnologia_controle_versao',\n",
    "  \"('P8_c_10 ', 'Plataformas de Data Apps (Streamlit, Shiny, Plotly Dash etc)')\": 'ds_tecnologia_data_apps',\n",
    "  \"('P8_c_11 ', 'Ferramentas de estatística avançada como SPSS, SAS, etc.')\": 'ds_tecnologia_estatistica_avancada',\n",
    "  \"('P8_d ', 'Em qual das opções abaixo você gasta a maior parte do seu tempo no trabalho?')\": 'ds_maior_tempo_gasto',\n",
    "\n",
    "\n",
    "  #restante\n",
    "  \"('P4_c_1 ', 'Dados relacionais (estruturados em bancos SQL)')\": 'fonte_dados_principal_relacionais',\n",
    "  \"('P4_c_2 ', 'Dados armazenados em bancos NoSQL')\": 'fonte_dados_principal_nosql',\n",
    "  \"('P4_c_3 ', 'Imagens')\": 'fonte_dados_principal_imagens',\n",
    "  \"('P4_c_4 ', 'Textos/Documentos')\": 'fonte_dados_principal_textos',\n",
    "  \"('P4_c_5 ', 'Vídeos')\": 'fonte_dados_principal_videos',\n",
    "  \"('P4_c_6 ', 'Áudios')\": 'fonte_dados_principal_audios',\n",
    "  \"('P4_c_7 ', 'Planilhas')\": 'fonte_dados_principal_planilhas',\n",
    "  \"('P4_c_8 ', 'Dados georeferenciados')\": 'fonte_dados_principal_geo',\n",
    "  \n",
    "  # === FERRAMENTAS ETL (Engenheiro de Dados) ===\n",
    "  \"('P6_b_1 ', 'Scripts Python')\": 'de_etl_scripts_python',\n",
    "  \"('P6_b_2 ', 'SQL & Stored Procedures')\": 'de_etl_sql_procedures',\n",
    "  \"('P6_b_3 ', 'Apache Airflow')\": 'de_etl_airflow',\n",
    "  \"('P6_b_4 ', 'Luigi')\": 'de_etl_luigi',\n",
    "  \"('P6_b_5 ', 'AWS Glue')\": 'de_etl_aws_glue',\n",
    "  \"('P6_b_6 ', 'Talend')\": 'de_etl_talend',\n",
    "  \"('P6_b_7 ', 'Pentaho')\": 'de_etl_pentaho',\n",
    "  \"('P6_b_8 ', 'Alteryx')\": 'de_etl_alteryx',\n",
    "  \"('P6_b_9 ', 'Stitch')\": 'de_etl_stitch',\n",
    "  \"('P6_b_10 ', 'Fivetran')\": 'de_etl_fivetran',\n",
    "  \"('P6_b_11 ', 'Google Dataflow')\": 'de_etl_google_dataflow',\n",
    "  \"('P6_b_12 ', 'Oracle Data Integrator')\": 'de_etl_oracle_di',\n",
    "  \"('P6_b_13 ', 'IBM DataStage')\": 'de_etl_ibm_datastage',\n",
    "  \"('P6_b_14 ', 'SAP BW ETL')\": 'de_etl_sap_bw',\n",
    "  \"('P6_b_15 ', 'SQL Server Integration Services (SSIS)')\": 'de_etl_ssis',\n",
    "  \"('P6_b_16 ', 'SAS Data Integration')\": 'de_etl_sas_di',\n",
    "  \"('P6_b_17 ', 'Qlik Sense')\": 'de_etl_qlik_sense',\n",
    "  \"('P6_b_18 ', 'Knime')\": 'de_etl_knime',\n",
    "  \"('P6_b_19 ', 'Databricks')\": 'de_etl_databricks',\n",
    "  \"('P6_b_19 ', 'Não utilizo ferramentas de ETL')\": 'de_etl_nenhuma', # Nota: Chave duplicada na sua lista, mas mapeada para segurança.\n",
    "\n",
    "  # === FERRAMENTAS QUALIDADE DE DADOS (Engenheiro de Dados) ===\n",
    "  \"('P6_g_1 ', 'great_expectations')\": 'de_qualidade_great_expectations',\n",
    "  \"('P6_g_2 ', 'dbt')\": 'de_qualidade_dbt',\n",
    "  \"('P6_g_3 ', 'AWS Deequ')\": 'de_qualidade_aws_deequ',\n",
    "  \"('P6_g_4 ', 'Apache Griffin')\": 'de_qualidade_apache_griffin',\n",
    "  \"('P6_g_5 ', 'Datafold')\": 'de_qualidade_datafold',\n",
    "  \"('P6_g_6 ', 'Amundsen')\": 'de_qualidade_amundsen',\n",
    "  \"('P6_g_7 ', 'Monte Carlo')\": 'de_qualidade_monte_carlo',\n",
    "  \"('P6_g_8 ', 'SODA')\": 'de_qualidade_soda',\n",
    "  \"('P6_g_9 ', 'Big Eye')\": 'de_qualidade_big_eye',\n",
    "  \"('P6_g_10 ', 'Data Band')\": 'de_qualidade_data_band',\n",
    "  \"('P6_g_11 ', 'Anomalo')\": 'de_qualidade_anomalo',\n",
    "  \"('P6_g_l ', 'Metaplane')\": 'de_qualidade_metaplane',\n",
    "  \"('P6_g_m ', 'Acceldata')\": 'de_qualidade_acceldata',\n",
    "  \n",
    "  # === MAIOR TEMPO GASTO (Engenheiro de Dados) ===\n",
    "  \"('P6_h_1 ', 'Desenvolvendo pipelines de dados utilizando linguagens de programação como Python, Scala, Java etc.')\": 'de_maior_tempo_pipelines_codigo',\n",
    "  \"('P6_h_2 ', 'Realizando construções de ETL's em ferramentas como Pentaho, Talend, Dataflow etc.')\": 'de_maior_tempo_etl_ferramentas',\n",
    "  \"('P6_h_3 ', 'Criando consultas através da linguagem SQL para exportar informações e compartilhar com as áreas de negócio.')\": 'de_maior_tempo_consultas_sql',\n",
    "  \"('P6_h_4 ', 'Atuando na integração de diferentes fontes de dados através de plataformas proprietárias como Stitch Data, Fivetran etc.')\": 'de_maior_tempo_integracao_plataformas',\n",
    "  \"('P6_h_5 ', 'Modelando soluções de arquitetura de dados, criando componentes de ingestão de dados, transformação e recuperação da informação.')\": 'de_maior_tempo_modelagem_arquitetura',\n",
    "  \"('P6_h_6 ', 'Desenvolvendo/cuidando da manutenção de repositórios de dados baseados em streaming de eventos como Data Lakes e Data Lakehouses.')\": 'de_maior_tempo_manutencao_datalakes',\n",
    "  \"('P6_h_7 ', 'Atuando na modelagem dos dados, com o objetivo de criar conjuntos de dados como Data Warehouses, Data Marts etc.')\": 'de_maior_tempo_modelagem_dados',\n",
    "  \"('P6_h_8 ', 'Cuidando da qualidade dos dados, metadados e dicionário de dados.')\": 'de_maior_tempo_qualidade_dados',\n",
    "  \"('P6_h_9 ', 'Nenhuma das opções listadas refletem meu dia a dia.')\": 'de_maior_tempo_nenhuma_das_opcoes',\n",
    "\n",
    "  # === FERRAMENTAS ETL (Analista de Dados) ===\n",
    "  \"('P7_b_1 ', 'Scripts Python')\": 'da_etl_scripts_python',\n",
    "  \"('P7_b_2 ', 'SQL & Stored Procedures')\": 'da_etl_sql_procedures',\n",
    "  \"('P7_b_3 ', 'Apache Airflow')\": 'da_etl_airflow',\n",
    "  \"('P7_b_4 ', 'Luigi')\": 'da_etl_luigi',\n",
    "  \"('P7_b_5 ', 'AWS Glue')\": 'da_etl_aws_glue',\n",
    "  \"('P7_b_6 ', 'Talend')\": 'da_etl_talend',\n",
    "  \"('P7_b_7 ', 'Pentaho')\": 'da_etl_pentaho',\n",
    "  \"('P7_b_8 ', 'Alteryx')\": 'da_etl_alteryx',\n",
    "  \"('P7_b_9 ', 'Stitch')\": 'da_etl_stitch',\n",
    "  \"('P7_b_10 ', 'Fivetran')\": 'da_etl_fivetran',\n",
    "  \"('P7_b_11 ', 'Google Dataflow')\": 'da_etl_google_dataflow',\n",
    "  \"('P7_b_12 ', 'Oracle Data Integrator')\": 'da_etl_oracle_di',\n",
    "  \"('P7_b_13 ', 'IBM DataStage')\": 'da_etl_ibm_datastage',\n",
    "  \"('P7_b_14 ', 'SAP BW ETL')\": 'da_etl_sap_bw',\n",
    "  \"('P7_b_15 ', 'SQL Server Integration Services (SSIS)')\": 'da_etl_ssis',\n",
    "  \"('P7_b_16 ', 'SAS Data Integration')\": 'da_etl_sas_di',\n",
    "  \"('P7_b_17 ', 'Qlik Sense')\": 'da_etl_qlik_sense',\n",
    "  \"('P7_b_18 ', 'Knime')\": 'da_etl_knime',\n",
    "  \"('P7_b_19 ', 'Databricks')\": 'da_etl_databricks',\n",
    "  \"('P7_b_20 ', 'Não utilizo ferramentas de ETL')\": 'da_etl_nenhuma',\n",
    "\n",
    "  # === FERRAMENTAS AUTONOMIA NEGÓCIOS (Analista de Dados) ===\n",
    "  \"('P7_c_1 ', 'Ferramentas de AutoML como H2O.ai, Data Robot, BigML etc.')\": 'da_autonomia_ferramentas_automl',\n",
    "  '(\\'P7_c_2 \\', \\'\"\"Point and Click\"\" Analytics como Alteryx, Knime, Rapidminer etc.\\')': 'da_autonomia_ferramentas_point_and_click',\n",
    "  \"('P7_c_3 ', 'Product metricts & Insights como Mixpanel, Amplitude, Adobe Analytics.')\": 'da_autonomia_ferramentas_product_insights',\n",
    "  \"('P7_c_4 ', 'Ferramentas de análise dentro de ferramentas de CRM como Salesforce Einstein Anaytics ou Zendesk dashboards.')\": 'da_autonomia_ferramentas_crm_analytics',\n",
    "  \"('P7_c_5 ', 'Minha empresa não utiliza essas ferramentas.')\": 'da_autonomia_ferramentas_nenhuma',\n",
    "  \"('P7_c_6 ', 'Não sei informar.')\": 'da_autonomia_ferramentas_nao_sabe',\n",
    "\n",
    "  # === MAIOR TEMPO GASTO (Analista de Dados) ===\n",
    "  \"('P7_d_1 ', 'Processando e analisando dados utilizando linguagens de programação como Python, R etc.')\": 'da_maior_tempo_analise_codigo',\n",
    "  \"('P7_d_2 ', 'Realizando construções de dashboards em ferramentas de BI como PowerBI, Tableau, Looker, Qlik etc.')\": 'da_maior_tempo_dashboards_bi',\n",
    "  \"('P7_d_3 ', 'Criando consultas através da linguagem SQL para exportar informações e compartilhar com as áreas de negócio.')\": 'da_maior_tempo_consultas_sql',\n",
    "  \"('P7_d_4 ', 'Utilizando API's para extrair dados e complementar minhas análises.')\": 'da_maior_tempo_extracao_api',\n",
    "  \"('P7_d_5 ', 'Realizando experimentos e estudos utilizando metodologias estatísticas como teste de hipótese, modelos de regressão etc.')\": 'da_maior_tempo_estatistica_testes',\n",
    "  \"('P7_d_6 ', 'Desenvolvendo/cuidando da manutenção de ETL's utilizando tecnologias como Talend, Pentaho, Airflow, Dataflow etc.')\": 'da_maior_tempo_manutencao_etl',\n",
    "  \"('P7_d_7 ', 'Atuando na modelagem dos dados, com o objetivo de criar conjuntos de dados, Data Warehouses, Data Marts etc.')\": 'da_maior_tempo_modelagem_dados',\n",
    "  \"('P7_d_8 ', 'Desenvolvendo/cuidando da manutenção de planilhas do Excel ou Google Sheets para atender as áreas de negócio.')\": 'da_maior_tempo_manutencao_planilhas',\n",
    "  \"('P7_d_9 ', 'Utilizando ferramentas avançadas de estatística como SAS, SPSS, Stata etc, para realizar análises.')\": 'da_maior_tempo_estatistica_avancada',\n",
    "  \"('P7_d_10 ', 'Nenhuma das opções listadas refletem meu dia a dia.')\": 'da_maior_tempo_nenhuma_das_opcoes',\n",
    "  \n",
    "  # === MAIOR TEMPO GASTO (Cientista de Dados) ===\n",
    "  \"('P8_d_1 ', 'Estudos Ad-hoc com o objetivo de confirmar hipóteses, realizar modelos preditivos, forecasts, análise de cluster para resolver problemas pontuais e responder perguntas das áreas de negócio.')\": 'ds_maior_tempo_estudos_ad_hoc',\n",
    "  \"('P8_d_2 ', 'Coletando e limpando os dados que uso para análise e modelagem.')\": 'ds_maior_tempo_coleta_limpeza',\n",
    "  \"('P8_d_3 ', 'Entrando em contato com os times de negócio para definição do problema, identificar a solução e apresentação de resultados.')\": 'ds_maior_tempo_contato_negocios',\n",
    "  \"('P8_d_4 ', 'Desenvolvendo modelos de Machine Learning com o objetivo de colocar em produção em sistemas (produtos de dados).')\": 'ds_maior_tempo_desenvolvimento_ml',\n",
    "  \"('P8_d_5 ', 'Colocando modelos em produção, criando os pipelines de dados, APIs de consumo e monitoramento.')\": 'ds_maior_tempo_ml_em_producao',\n",
    "  \"('P8_d_6 ', 'Cuidando da manutenção de modelos de Machine Learning já em produção, atuando no monitoramento, ajustes e refatoração quando necessário.')\": 'ds_maior_tempo_manutencao_ml',\n",
    "  \"('P8_d_7 ', 'Realizando construções de dashboards em ferramentas de BI como PowerBI, Tableau, Looker, Qlik, etc.')\": 'ds_maior_tempo_dashboards_bi',\n",
    "  \"('P8_d_8 ', 'Utilizando ferramentas avançadas de estatística como SAS, SPSS, Stata etc, para realizar análises.')\": 'ds_maior_tempo_estatistica_avancada',\n",
    "  \"('P8_d_9 ', 'Criando e dando manutenção em ETLs, DAGs e automações de pipelines de dados.')\": 'ds_maior_tempo_manutencao_etl',\n",
    "  \"('P8_d_10 ', 'Criando e gerenciando soluções de Feature Store e cultura de MLOps.')\": 'ds_maior_tempo_feature_store_mlops',\n",
    "  \"('P8_d_11 ', 'Criando e mantendo a infra que meus modelos e soluções rodam (clusters, servidores, API, containers, etc.)')\": 'ds_maior_tempo_infraestrutura'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a2ef29f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mapa_renomeacao_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0435b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2022_kaggle_renomeado = df_2022_kaggle.rename(columns=mapa_renomeacao_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "270b6c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id_participante', 'idade', 'faixa_idade', 'genero', 'etnia', 'pcd', 'experiencia_prejudicada', 'prejudicado_aspectos_lista', 'vive_no_brasil', 'estado_residencia', 'uf_residencia', 'regiao_residencia', 'mudou_de_estado', 'regiao_origem', 'nivel_ensino', 'area_formacao', 'situacao_trabalho', 'setor_atuacao', 'tamanho_empresa', 'atua_como_gestor', 'cargo_gestor', 'cargo_atual', 'nivel_hierarquico', 'faixa_salarial', 'experiencia_dados_anos', 'experiencia_ti_anos', 'satisfacao_trabalho', 'motivos_insatisfacao', 'insatisfacao_fator_falta_crescimento', 'insatisfacao_fator_salario_defasado', 'insatisfacao_fator_relacao_gestor', 'insatisfacao_fator_desejo_mudar_area', 'insatisfacao_fator_beneficios', 'insatisfacao_fator_ambiente_ruim', 'insatisfacao_fator_baixa_maturidade_empresa', 'entrevistas_ultimos_6m', 'planos_mudar_emprego', 'criterios_escolha_emprego', 'criterio_escolha_remuneracao', 'criterio_escolha_beneficios', 'criterio_escolha_proposito', 'criterio_escolha_flexibilidade', 'criterio_escolha_ambiente', 'criterio_escolha_aprendizado', 'criterio_escolha_plano_carreira', 'criterio_escolha_maturidade_empresa', 'criterio_escolha_qualidade_gestores', 'criterio_escolha_reputacao_empresa', 'modelo_trabalho_atual', 'modelo_trabalho_ideal', 'atitude_retorno_presencial', 'empresa_teve_layoff', 'tamanho_equipe_dados', 'empresa_cargos_dados_lista', 'empresa_tem_analytics_engineer', 'empresa_tem_engenheiro_dados', 'empresa_tem_analista_dados', 'empresa_tem_cientista_dados', 'empresa_tem_dba', 'empresa_tem_analista_bi', 'empresa_tem_arquiteto_dados', 'empresa_tem_dpm', 'empresa_tem_business_analyst', 'gestor_responsabilidades_lista', 'gestor_resp_visao_longo_prazo', 'gestor_resp_treinamentos', 'gestor_resp_contratacao', 'gestor_resp_decisao_ferramentas', 'gestor_resp_head_engenharia', 'gestor_resp_head_analise_bi', 'gestor_resp_head_ia_ml', 'gestor_resp_atua_tecnico', 'gestor_resp_gestao_projetos', 'gestor_resp_gestao_produtos', 'gestor_resp_gestao_pessoas', 'desafios_gestor', 'gestor_desafio_contratar_talentos', 'gestor_desafio_reter_talentos', 'gestor_desafio_obter_investimento', 'gestor_desafio_gestao_remota', 'gestor_desafio_projetos_multiarea', 'gestor_desafio_qualidade_confiabilidade', 'gestor_desafio_volume_dados', 'gestor_desafio_gerar_valor_negocio', 'gestor_desafio_ml_em_producao', 'gestor_desafio_gerenciar_expectativas', 'gestor_desafio_manutencao_producao', 'gestor_desafio_inovar', 'gestor_desafio_garantir_roi', 'gestor_desafio_dividir_tempo_tecnico_gestao', 'atuacao_funcao', 'atuacao_em_dados', 'fontes_dados_lista', 'fonte_dados_usa_relacionais', 'fonte_dados_usa_nosql', 'fonte_dados_usa_imagens', 'fonte_dados_usa_textos', 'fonte_dados_usa_videos', 'fonte_dados_usa_audios', 'fonte_dados_usa_planilhas', 'fonte_dados_usa_geo', 'fonte_dados_principal', 'fonte_dados_principal_relacionais', 'fonte_dados_principal_nosql', 'fonte_dados_principal_imagens', 'fonte_dados_principal_textos', 'fonte_dados_principal_videos', 'fonte_dados_principal_audios', 'fonte_dados_principal_planilhas', 'fonte_dados_principal_geo', 'linguagens_usadas_dia_a_dia', 'linguagem_usa_sql', 'linguagem_usa_r', 'linguagem_usa_python', 'linguagem_usa_c_cplusplus_csharp', 'linguagem_usa_dotnet', 'linguagem_usa_java', 'linguagem_usa_julia', 'linguagem_usa_sas_stata', 'linguagem_usa_vba', 'linguagem_usa_scala', 'linguagem_usa_matlab', 'linguagem_usa_php', 'linguagem_usa_javascript', 'linguagem_usa_nenhuma', 'linguagem_principal', 'linguagem_preferida', 'bancos_dados_usados_dia_a_dia', 'banco_dados_usa_mysql', 'banco_dados_usa_oracle', 'banco_dados_usa_sql_server', 'banco_dados_usa_aurora_rds', 'banco_dados_usa_dynamodb', 'banco_dados_usa_coachdb', 'banco_dados_usa_cassandra', 'banco_dados_usa_mongodb', 'banco_dados_usa_mariadb', 'banco_dados_usa_datomic', 'banco_dados_usa_s3', 'banco_dados_usa_postgresql', 'banco_dados_usa_elasticsearch', 'banco_dados_usa_db2', 'banco_dados_usa_access', 'banco_dados_usa_sqlite', 'banco_dados_usa_sybase', 'banco_dados_usa_firebase', 'banco_dados_usa_vertica', 'banco_dados_usa_redis', 'banco_dados_usa_neo4j', 'banco_dados_usa_bigquery', 'banco_dados_usa_firestore', 'banco_dados_usa_redshift', 'banco_dados_usa_athena', 'banco_dados_usa_snowflake', 'banco_dados_usa_databricks', 'banco_dados_usa_hbase', 'banco_dados_usa_presto', 'banco_dados_usa_splunk', 'banco_dados_usa_sap_hana', 'banco_dados_usa_hive', 'banco_dados_usa_firebird', 'clouds_utilizadas', 'cloud_preferida', 'cloud_usa_azure', 'cloud_usa_aws', 'cloud_usa_gcp', 'ferramentas_bi_usadas_dia_a_dia', 'bi_usa_powerbi', 'bi_usa_qlik', 'bi_usa_tableau', 'bi_usa_metabase', 'bi_usa_superset', 'bi_usa_redash', 'bi_usa_microstrategy', 'bi_usa_ibm_cognos', 'bi_usa_sap_bi', 'bi_usa_oracle_bi', 'bi_usa_quicksight', 'bi_usa_salesforce_einstein', 'bi_usa_mode', 'bi_usa_alteryx', 'bi_usa_birst', 'bi_usa_looker', 'bi_usa_google_data_studio', 'bi_usa_sas_va', 'bi_usa_grafana', 'bi_usa_tibco', 'bi_usa_pentaho', 'bi_usa_excel_gsheets', 'bi_usa_nenhuma', 'objetivo_profissional', 'tipo_oportunidade_buscada', 'tempo_busca_emprego_meses', 'carreira_experiencia_processos_seletivos', 'de_rotina_lista', 'de_rotina_pipeline_codigo', 'de_rotina_etl_ferramentas', 'de_rotina_consultas_sql', 'de_rotina_integracao_plataformas', 'de_rotina_modelagem_arquitetura', 'de_rotina_manutencao_datalakes', 'de_rotina_modelagem_dados', 'de_rotina_qualidade_dados', 'de_rotina_nenhuma_das_opcoes', 'de_ferramentas_etl_lista', 'de_etl_scripts_python', 'de_etl_sql_procedures', 'de_etl_airflow', 'de_etl_luigi', 'de_etl_aws_glue', 'de_etl_talend', 'de_etl_pentaho', 'de_etl_alteryx', 'de_etl_stitch', 'de_etl_fivetran', 'de_etl_google_dataflow', 'de_etl_oracle_di', 'de_etl_ibm_datastage', 'de_etl_sap_bw', 'de_etl_ssis', 'de_etl_sas_di', 'de_etl_qlik_sense', 'de_etl_knime', 'de_etl_databricks', 'de_etl_nenhuma', 'de_empresa_possui_data_lake', 'de_empresa_tecnologia_data_lake', 'de_empresa_possui_data_warehouse', 'de_empresa_tecnologia_data_warehouse', 'de_ferramentas_qualidade_dados_lista', 'de_qualidade_great_expectations', 'de_qualidade_dbt', 'de_qualidade_aws_deequ', 'de_qualidade_apache_griffin', 'de_qualidade_datafold', 'de_qualidade_amundsen', 'de_qualidade_monte_carlo', 'de_qualidade_soda', 'de_qualidade_big_eye', 'de_qualidade_data_band', 'de_qualidade_anomalo', 'de_qualidade_metaplane', 'de_qualidade_acceldata', 'de_maior_tempo_gasto', 'de_maior_tempo_pipelines_codigo', 'de_maior_tempo_etl_ferramentas', 'de_maior_tempo_consultas_sql', 'de_maior_tempo_integracao_plataformas', 'de_maior_tempo_modelagem_arquitetura', 'de_maior_tempo_manutencao_datalakes', 'de_maior_tempo_modelagem_dados', 'de_maior_tempo_qualidade_dados', 'de_maior_tempo_nenhuma_das_opcoes', 'da_rotina_lista', 'da_rotina_analise_codigo', 'da_rotina_dashboards_bi', 'da_rotina_consultas_sql', 'da_rotina_extracao_api', 'da_rotina_estatistica_testes', 'da_rotina_manutencao_etl', 'da_rotina_modelagem_dados', 'da_rotina_manutencao_planilhas', 'da_rotina_estatistica_avancada', 'da_rotina_nenhuma_das_opcoes', 'da_ferramentas_etl_lista', 'da_etl_scripts_python', 'da_etl_sql_procedures', 'da_etl_airflow', 'da_etl_luigi', 'da_etl_aws_glue', 'da_etl_talend', 'da_etl_pentaho', 'da_etl_alteryx', 'da_etl_stitch', 'da_etl_fivetran', 'da_etl_google_dataflow', 'da_etl_oracle_di', 'da_etl_ibm_datastage', 'da_etl_sap_bw', 'da_etl_ssis', 'da_etl_sas_di', 'da_etl_qlik_sense', 'da_etl_knime', 'da_etl_databricks', 'da_etl_nenhuma', 'da_ferramentas_autonomia_negocios_lista', 'da_autonomia_ferramentas_automl', 'da_autonomia_ferramentas_point_and_click', 'da_autonomia_ferramentas_product_insights', 'da_autonomia_ferramentas_crm_analytics', 'da_autonomia_ferramentas_nenhuma', 'da_autonomia_ferramentas_nao_sabe', 'da_maior_tempo_gasto', 'da_maior_tempo_analise_codigo', 'da_maior_tempo_dashboards_bi', 'da_maior_tempo_consultas_sql', 'da_maior_tempo_extracao_api', 'da_maior_tempo_estatistica_testes', 'da_maior_tempo_manutencao_etl', 'da_maior_tempo_modelagem_dados', 'da_maior_tempo_manutencao_planilhas', 'da_maior_tempo_estatistica_avancada', 'da_maior_tempo_nenhuma_das_opcoes', 'ds_rotina_lista', 'ds_rotina_estudos_ad_hoc', 'ds_rotina_coleta_limpeza', 'ds_rotina_contato_negocios', 'ds_rotina_desenvolvimento_ml', 'ds_rotina_ml_em_producao', 'ds_rotina_manutencao_ml', 'ds_rotina_dashboards_bi', 'ds_rotina_estatistica_avancada', 'ds_rotina_manutencao_etl', 'ds_rotina_feature_store_mlops', 'ds_rotina_infraestrutura', 'ds_tecnicas_lista', 'ds_tecnica_regressao', 'ds_tecnica_classificacao_arvores_redes', 'ds_tecnica_sistemas_recomendacao', 'ds_tecnica_estatistica_bayesiana', 'ds_tecnica_nlp', 'ds_tecnica_estatistica_classica', 'ds_tecnica_markov_hmm', 'ds_tecnica_clusterizacao', 'ds_tecnica_series_temporais', 'ds_tecnica_reinforcement_learning', 'ds_tecnica_deteccao_fraude', 'ds_tecnica_visao_computacional', 'ds_tecnica_deteccao_churn', 'ds_tecnologias_lista', 'ds_tecnologia_ferramentas_bi', 'ds_tecnologia_planilhas', 'ds_tecnologia_dev_local', 'ds_tecnologia_dev_nuvem', 'ds_tecnologia_automl', 'ds_tecnologia_etl', 'ds_tecnologia_plataformas_ml', 'ds_tecnologia_feature_store', 'ds_tecnologia_controle_versao', 'ds_tecnologia_data_apps', 'ds_tecnologia_estatistica_avancada', 'ds_maior_tempo_gasto', 'ds_maior_tempo_estudos_ad_hoc', 'ds_maior_tempo_coleta_limpeza', 'ds_maior_tempo_contato_negocios', 'ds_maior_tempo_desenvolvimento_ml', 'ds_maior_tempo_ml_em_producao', 'ds_maior_tempo_manutencao_ml', 'ds_maior_tempo_dashboards_bi', 'ds_maior_tempo_estatistica_avancada', 'ds_maior_tempo_manutencao_etl', 'ds_maior_tempo_feature_store_mlops', 'ds_maior_tempo_infraestrutura', 'salario_medio_mensal', 'grupo_cargo', 'experiencia_anos_num', 'ano']\n"
     ]
    }
   ],
   "source": [
    "print(df_2022_kaggle_renomeado.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81709296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A lista original tem 357 colunas\n",
      "Foram renomeadas 353 colunas\n"
     ]
    }
   ],
   "source": [
    "print(f'A lista original tem {len(df_2022_kaggle.columns)} colunas')\n",
    "print(f'Foram renomeadas {len(mapa_renomeacao_2022)} colunas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59d81d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = PROCESSED_DATA_DIR / 'state_of_data_2022_rico_limpo.csv'\n",
    "df_2022_kaggle_renomeado.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae07e466",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
